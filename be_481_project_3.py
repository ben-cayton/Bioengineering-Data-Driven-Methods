# -*- coding: utf-8 -*-
"""be 481 project 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E88YdhM_lTVBihWu0XUNOfqdk3Y4E262
"""

from os.path import dirname, join as pjoin 
import torch
from torch import cuda
import pandas as pd
from skimage import io, transform
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils
from torchvision.transforms import Compose, ToTensor, CenterCrop, TenCrop, Lambda, Resize, Normalize
from torch import nn
from typing import Any

# This cell is used to compute the mean and std dev of the training set.
"""df_train = pd.read_csv('../input/be-481-project-03/proj3/train.csv')
# Store the pathway to the train folder, which contains the training image 
# files, in a variable.
directory_train = '../input/be-481-project-03/proj3/train'
# Create an empty array for each color channel with the number of elements
# equal to the number of images in the DataFrame "df_train".
R = np.zeros([df_train.shape[0]])
G = np.zeros([df_train.shape[0]])
B = np.zeros([df_train.shape[0]])
# Loop through the training image file names in the DataFrame "df_train"
# in order that they are in the DataFrame.
for idx, filename in enumerate(df_train["Id"]):
    # Cretae a variable for the current filename.
    filenames = pjoin(directory_train, filename)
    # Create a variable for the image pixel array.
    img = plt.imread(filenames)
    img_col_arrs = img[2]
    img_col = img_col_arrs[0]
    # Populate the color channel arrays with the pixel values for that channel.
    R[idx] = img_col[0]
    G[idx] = img_col[1]
    B[idx] = img_col[2]
# Compute the color channel-wise means and standard deviations.
r_train_mean = np.mean(R)
g_train_mean = np.mean(G)
b_train_mean = np.mean(B)
r_train_std = np.std(R)
g_train_std = np.std(G)
b_train_std = np.std(B)
# Print the results.
print('red train mean is %s' % r_train_mean)
print('green train mean is %s' % g_train_mean)
print('blue train mean is %s' % b_train_mean)
print('red train std is %s' % r_train_std)
print('green train std is %s' % g_train_std)
print('blue train std is %s' % b_train_std)"""

# This cell is used to compute the mean and std dev of the test set.
"""df_test = pd.read_csv('../input/be-481-project-03/proj3/sample-'
'submission.csv')
# Store the pathway to the train folder, which contains the training image 
# files, in a variable.
directory_test = '../input/be-481-project-03/proj3/test'
# Create an empty array for each color channel with the number of elements
# equal to the number of images in the DataFrame "df_test".
R = np.zeros([df_test.shape[0]])
G = np.zeros([df_test.shape[0]])
B = np.zeros([df_test.shape[0]])
# Create an  array containing the labels of the training images.
# Loop through the training image file names in the DatarFrame "df_train"
# in order that they are in the DataFrame. 
for idx, filename in enumerate(df_test["Id"]):
    # Cretae a variable for the current filename.
    filenames = pjoin(directory_test, filename)
    # Create a variable for the image pixel array.
    img = plt.imread(filenames)
    img_col_arrs = img[2]
    img_col = img_col_arrs[0]
    # Populate the color channel arrays with the pixel values for that channel.
    R[idx] = img_col[0]
    G[idx] = img_col[1]
    B[idx] = img_col[2]
# Compute the color channel-wise means and standard deviations.
r_test_mean = np.mean(R)
g_test_mean = np.mean(G)
b_test_mean = np.mean(B)
r_test_std = np.std(R)
g_test_std = np.std(G)
b_test_std = np.std(B)
print('red test mean is %s' % r_test_mean)
print('green test mean is %s' % g_test_mean)
print('blue test mean is %s' % b_test_mean)
print('red test std is %s' % r_test_std)
print('green test std is %s' % g_test_std)
print('blue test std is %s' % b_test_std)"""

class CancerImageDataset(Dataset):
    """Cancer image dataset"""

    def __init__(self, csv_file, root_dir, transform):
        
        self.labels_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.labels_frame)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.np.ndaray()

        img_name = pjoin(self.root_dir, 
                         self.labels_frame.iloc[idx, 0])
        image = io.imread(img_name)
        labels = self.labels_frame.iloc[idx, 1]

        if self.transform:
            image = self.transform(image)
        
        sample = {'image': image, 'labels': labels}

        return sample

# Transforms for data processing.
train_transforms = Compose([
            ToTensor(),
            CenterCrop(224),
            Resize(256),
            Normalize(mean=[r_train_mean, g_train_mean, b_train_mean], 
                                 std=[r_train_std, g_train_std, b_train_std]),
])

test_transforms = Compose([
            ToTensor(),
            CenterCrop(224),
            Resize(256),
            Normalize(mean=[r_test_mean, g_test_mean, b_test_mean], 
                                 std=[r_test_std, g_test_std, b_test_std]),
])

"""
# Augmentation transforms to increase the size of the dataset. 
# TenCrop takes snippets from the image of designated size from 
# the four corners, the center, and then again using the horizontally flipped 
# image. 

aug_transforms = Compose([
            ToTensor(),
            RandomCrop(224),
            Resize(256),
            TenCrop(224),
            Lambda(lambda crops: torch.stack([(crop) for crop in crops]))
])
"""

# Create the training and testing datasets. Trainval will be split into 
# training and validation sets.

trainval_data = CancerImageDataset('../input/be-481-project-03/proj3/'
                         'train.csv', '../input/be-481-project-03/'
                         'proj3/train', train_transforms)
test_data = CancerImageDataset('../input/be-481-project-03/proj3/sample-'
                        'submission.csv', '../input/be-481-project-03/'
                          'proj3/test', test_transforms)
# Split the trainval set into training and validation sets.
training_data, validation_data = torch.utils.data.random_split(
    trainval_data, [437, 109], generator=torch.Generator().manual_seed(20))

# Take a look at the distribution of classes in the 
# training and validations sets. 
# Create a dictionary with keys coresponding to the image labels
# and values corresponding to the meaning of the labels.
"""
labels_map = {0:'normal', 1:'benign', 2:'malignant'}
# Initiate a counter.
class_count = np.zeros(3)
# Loop through the validation set, print the number of images
# in each class
for idx in range(len(validation_data)):
    val_label = validation_data[idx]['labels']
    class_count[val_label] += 1
for idx, val in enumerate(class_count):
    print('Label {0} in validation set: {1}'.format(
        labels_map[idx], val))
# Re-initiate the counter.
class_count = np.zeros(3)
# Loop through the training set, print the number of images
# in each class
for idx in range(len(training_data)):
    train_label = training_data[idx]['labels']
    class_count[train_label] += 1
for idx, val in enumerate(class_count):
    print('Label {0} in training set: {1}'.format(
        labels_map[idx], val))"""

# Create the data loader to prepare for training. 
# Shuffle the data to create a balanced training experience.
train_dataloader = DataLoader(training_data, batch_size=1, shuffle=True)
val_dataloader = DataLoader(training_data, batch_size=1, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False)

__all__ = ['AlexNet', 'alexnet']


model_urls = {
    'alexnet': 'https://download.pytorch.org/models/'
    'alexnet-owt-7be5be79.pth',
}


class AlexNet(nn.Module):

    def __init__(self, num_classes: int = 3) -> None:
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(64, 192, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(192, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )
        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x


def alexnet(pretrained: bool = False, progress: bool = True, 
            **kwargs: Any) -> AlexNet:
    r"""AlexNet model architecture from the
    `"One weird trick..." <https://arxiv.org/abs/1404.5997>`_ paper.
    Args:
        pretrained (bool): If True, returns a model 
        pre-trained on ImageNet
        progress (bool): If True, displays a progress bar 
        of the download to stderr
    """
    model = AlexNet(**kwargs)
    if pretrained:
        state_dict = load_state_dict_from_url(model_urls['alexnet'],
                                              progress=progress)
        model.load_state_dict(state_dict)
    return model

# print number of GPU's available
print(torch. cuda. device_count())

# assign the AlexNet model to a variable
model = AlexNet()

# assign the CUDA GPU to a variable 
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

# send the model to the GPU
model.to(device)

# This cell contains the training and testing loops. 
def train_loop(dataloader, model, cost_fn, optimizer, device):
    size = len(dataloader.dataset)
    for batch, data in enumerate(dataloader):
        # Compute prediction and cost function
        X = data['image'].to(device)
        y = data['labels'].to(device)
        pred = model(X)
        cost = cost_fn(pred, y)

        # Backpropagation
        optimizer.zero_grad()
        cost.backward()
        optimizer.step()

        if batch % 100 == 0:
            cost, current = cost.item(), batch * len(X)
            print(f"cost: {cost:>7f}  [{current:>5d}/{size:>5d}]")

def test_loop(dataloader, model, cost_fn, device):
    size = len(dataloader.dataset)
    test_cost, correct = 0, 0
    with torch.no_grad():
        for data in dataloader:
            X = data['image'].to(device)
            y = data['labels'].to(device)
            pred = model(X)
            test_cost += cost_fn(pred, y).item()
            correct += (pred.argmax(1) == y).type(torch.float).sum().item()

    test_cost /= size
    correct /= size
    print(f"Test Error: \n Accuracy: {(100*correct):>0.1f}%,"
          + f"Avg loss: {test_cost:>8f} \n")
    return test_cost, correct

# This cell conducts trining and validation of the model 
# using the training and testing loops on the training and 
# validation data. 
lr = 1e-4
epochs = 37
cost_tr = np.zeros(epochs)
cost_val = np.zeros(epochs)
acc_tr = np.zeros(epochs)
acc_val = np.zeros(epochs)
cost_fn = nn.CrossEntropyLoss().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=lr)

for t in range(epochs):
    print(f"Epoch {t+1}\n-------------------------------")
    # Train for an epoch
    train_loop(train_dataloader, model, cost_fn, optimizer, device)
    # Save the model in its current state
    torch.save(model.state_dict(), './model-v1-ep{0}'.format(t))
    # Check training performance
    cost, acc = test_loop(train_dataloader, model, cost_fn, device)
    cost_tr[t] = cost
    acc_tr[t] = acc
    # Check validation performance
    cost, acc = test_loop(val_dataloader, model, cost_fn, device)
    cost_val[t] = cost
    acc_val[t] = acc
print("Training Done!")

# Plot the learning curve
x_data = np.array(range(epochs))
plt.figure(figsize=(12, 6))
plt.subplot(121)
plt.plot(x_data, cost_tr, linewidth=1)
plt.plot(x_data, cost_val, linewidth=1)
plt.xlabel('epoch')
plt.ylabel('cost')
plt.legend(['train', 'val'])
plt.subplot(122)
plt.plot(x_data, acc_tr, linewidth=1)
plt.plot(x_data, acc_val, linewidth=1)
plt.xlabel('epoch')
plt.ylabel('Accuracy')
plt.legend(['train', 'val'])
plt.show()

# load the desired sate of the trained and validated model
# and send it to the device
model.load_state_dict(torch.load('model-v1-ep36'))
model.eval()
model.to(device)

# Calculate the predicted labels of the test data. 
# This is done by taking the maximum probability of a predicted label 
# for a given image and assigning that image a label corresponding to 
# the index of the variable 'labels', which is 0, 1, or 2. 
pred = np.zeros((len(test_data)))
labels = np.arange(0,3)
for idx, data in enumerate(test_data):
    image = torch.unsqueeze(data["image"], 0).to(device)
    pred_tensor = model(image)
    max_value, index_of_max_value = torch.max(pred_tensor, 1)
    pred[idx] = labels[index_of_max_value]
int_array = pred.astype(int)

# Save the predicted labels and the image IDs to a CSV for submisison
df_test = pd.read_csv('../input/be-481-project-03/proj3/sample-''
                      'submission.csv')
df = pd.DataFrame({"Id":df_test["Id"],"Predicted":int_array})
df.to_csv('outIII.csv', index=False)